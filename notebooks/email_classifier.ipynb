{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Filtering for the ENRON Spam Datasets\n",
    "\n",
    "We will train a Naive Bayes Classifier on the ENRON Spam Datasets [1]. Naive Bayes is a popular choice for spam filtering due to its simplicity and accuracy within the spam filtering domain. It is called \"naive\" because we assume that word appearances are independent within an email. This is not the case but it still leads to good performance.\n",
    "\n",
    "We represent each email as a vector of word counts, where only the 1000 most important words within the training set are considered (see \"Preprocessing for the Email Classifier\"). Let $F = \\{t_1, t_2, \\dots, t_m\\}$ denote the set of words that we chose ($m = 1000$). By Bayes' theorem, the probability that an email with vector $\\mathbf{x} = \\langle x_1, x_2, \\dots, x_m \\rangle$ is *spam* is\n",
    "\n",
    "$$\n",
    "p(s \\mid \\mathbf{x}) = \\frac{p(s) \\cdot p(\\mathbf{x} \\mid s)}{p(s) \\cdot (\\mathbf{x} \\mid s) + p(h) \\cdot p(\\mathbf{x} \\mid h)},\n",
    "$$\n",
    "\n",
    "where $s$ denotes the spam category and $h$ denotes the ham category (not spam). We classify a message $\\mathbf{x}$ as spam whenever $p(s \\mid \\mathbf{x})$ is greater than some threshold $T$. As we shall see later, varying $T$ will have different consequences.\n",
    "\n",
    "Each email $e$ can be seen as independently picking $|e|$ words from $F$ with replacement. Therefore, $p(\\mathbf{x} \\mid c)$ is the multinomial distribution:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x} \\mid c) = p(|e|) \\cdot |e|! \\cdot \\prod_{i=1}^m{\\frac{p(t_i \\mid c)^{x_i}}{x_i!}},\n",
    "$$\n",
    "\n",
    "where we have made another common assumption [1] that $|e|$ does not depend on the category $c$. This is incorrect because the length of a message can give us info about whether that message is spam. The probability of an email $\\mathbf{x}$ being spam is now\n",
    "\n",
    "$$\n",
    "p(s \\mid \\mathbf{x}) = \\frac{p(s) \\cdot \\prod_{i=1}^m{p(t_i \\mid s)^{x_i}}}{\\sum_{c \\in \\{s, h\\}}{p(c) \\cdot \\prod_{i=1}^m{p(t_i \\mid c)^{x_i}}}}.\n",
    "$$\n",
    "\n",
    "The empirical probability of $p(t \\mid c)$ is $N_{t, c} / N_c$, where $N_{t, c}$ is the number of occurrences of word $t$ in the in the training messages of category $c,$ and $N_c$ is the total occurrences of every word within the category $c.$ We apply [laplace smoothing](https://en.wikipedia.org/wiki/Additive_smoothing) with $\\alpha = 1$ [1] and estimate $p(t \\mid c)$ as\n",
    "\n",
    "$$\n",
    "p(t \\mid c) = \\frac{1 + N_{t, c}}{m + N_c}.\n",
    "$$\n",
    "\n",
    "## Building the classifier\n",
    "\n",
    "The train and test data have already been preprocessed into word count vectors based on the best 500 words information gain wise. We want to precalculate $p(s),$ $p(h),$ and all $p(t \\mid c)$ in order to keep our classifier from depending on the entire training set. We build a table `p` where `p[word]['spam']` gives $p(t \\mid s)$ for a given `word`. `p['ANY']['spam']` gives $p(s),$ the probability that any message is spam. `p[word]['ham']` and `p['ANY']['ham']` behave similarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_hdf('data/enron/spam_filter_train_preprocessed.h5')\n",
    "test_data = pd.read_hdf('data/enron/spam_filter_test_preprocessed.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ANY</th>\n",
       "      <th>http</th>\n",
       "      <th>your</th>\n",
       "      <th>more</th>\n",
       "      <th>here</th>\n",
       "      <th>no</th>\n",
       "      <th>our</th>\n",
       "      <th>all</th>\n",
       "      <th>www</th>\n",
       "      <th>com</th>\n",
       "      <th>...</th>\n",
       "      <th>reform</th>\n",
       "      <th>pr</th>\n",
       "      <th>illustrator</th>\n",
       "      <th>otcbb</th>\n",
       "      <th>assurance</th>\n",
       "      <th>opinions</th>\n",
       "      <th>macromedia</th>\n",
       "      <th>revenues</th>\n",
       "      <th>tax</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <th>0</th>\n",
       "      <td>0.2913</td>\n",
       "      <td>0.005766</td>\n",
       "      <td>0.01161</td>\n",
       "      <td>0.003501</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>0.006224</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>0.005635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <th>0</th>\n",
       "      <td>0.7087</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.00715</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ANY      http     your      more      here        no       our  \\\n",
       "spam 0  0.2913  0.005766  0.01161  0.003501  0.003253  0.004352  0.006224   \n",
       "ham  0  0.7087  0.000825  0.00715  0.001197  0.001267  0.002216  0.003552   \n",
       "\n",
       "             all       www       com  ...    reform        pr  illustrator  \\\n",
       "spam 0  0.005327  0.003573  0.005635  ...  0.000137  0.000151     0.000183   \n",
       "ham  0  0.003618  0.000546  0.009366  ...  0.000004  0.000004     0.000004   \n",
       "\n",
       "           otcbb  assurance  opinions  macromedia  revenues       tax  \\\n",
       "spam 0  0.000242   0.000229  0.000170    0.000314  0.000242  0.000196   \n",
       "ham  0  0.000004   0.000004  0.000004    0.000004  0.000019  0.000399   \n",
       "\n",
       "           value  \n",
       "spam 0  0.000236  \n",
       "ham  0  0.000236  \n",
       "\n",
       "[2 rows x 1001 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = train_data.drop(['SPAM'], axis=1)\n",
    "def probabilities(category):\n",
    "    individual_occurrences = category.sum()\n",
    "    all_occurrences = individual_occurrences.sum()\n",
    "\n",
    "    return (1 + individual_occurrences) / (len(category.columns) + all_occurrences)\n",
    "\n",
    "spam_probabilities = probabilities(word_counts[train_data['SPAM']])\n",
    "ham_probabilities = probabilities(word_counts[np.logical_not(train_data['SPAM'])])\n",
    "\n",
    "prob_spam = len(word_counts[train_data['SPAM']]) / len(word_counts)\n",
    "prob_ham = 1. - prob_spam\n",
    "\n",
    "p_spam = pd.concat([pd.DataFrame({'ANY': [prob_spam]}).transpose(), spam_probabilities])\n",
    "p_ham = pd.concat([pd.DataFrame({'ANY': [prob_ham]}).transpose(), ham_probabilities])\n",
    "\n",
    "p = pd.concat({'spam': p_spam, 'ham': p_ham}, axis=1).transpose()\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the table for later use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.to_hdf('resources/enron_spam_filter_table.h5', key='enron_spam_filter_table', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the classifier\n",
    "\n",
    "Let's see how the classifier would fair if the threshold for classifying spam was 0.5. This would mean that we would classify an email as spam anytime that it was more likely than being ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 88.6%\n"
     ]
    }
   ],
   "source": [
    "test_word_counts = test_data.drop(['SPAM'], axis=1)\n",
    "\n",
    "spam_term = p.loc['spam'].drop(['ANY'], axis=1).to_numpy() ** test_word_counts\n",
    "spam_term = p['ANY']['spam'].to_numpy() * spam_term.prod(axis=1)\n",
    "\n",
    "ham_term = p.loc['ham'].drop(['ANY'], axis=1).to_numpy() ** test_word_counts\n",
    "ham_term = p['ANY']['ham'].to_numpy() * ham_term.prod(axis=1)\n",
    "\n",
    "prob_spam = spam_term / (spam_term + ham_term)\n",
    "prob_spam = prob_spam.fillna(p['ANY']['spam'])\n",
    "\n",
    "is_spam = prob_spam > 0.5\n",
    "\n",
    "correct = test_data['SPAM'] == is_spam\n",
    "\n",
    "accuracy = correct.sum() / len(test_data) * 100\n",
    "\n",
    "print('Classification Accuracy: ' + f'{accuracy:.1f}' + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a classification accuracy of 88.6% for $T = 0.5$. This may be decent enough, but lets look at the messages that were classified incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of ham incorrectly filtered: 13.4%. Percentage of spam unfiltered: 6.2%.\n"
     ]
    }
   ],
   "source": [
    "incorrect = test_data.loc[test_data['SPAM'] != is_spam]\n",
    "\n",
    "filtered_ham = incorrect['SPAM'].sum() / np.logical_not(test_data['SPAM']).sum() * 100\n",
    "unfiltered_spam = np.logical_not(incorrect['SPAM']).sum() / test_data['SPAM'].sum() * 100\n",
    "\n",
    "print('Percentage of ham incorrectly filtered: ' + f'{filtered_ham:.1f}' + '%. Percentage of spam unfiltered: ' + f'{unfiltered_spam:.1f}' + '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, most of the error in our filter comes from incorrectly filtering out legitimate messages. Our filter did a good job at catching spam, only letting 6.2% get through, but this comes at the cost of filtering out a large amount of legitimate messages. An email service would not be very user friendly if the user's messages had more than a 1 in 10 chance of being put into the spam folder. Therefore, we need a better measure of the filter's performance.\n",
    "\n",
    "## Precision vs. Recall\n",
    "\n",
    "We want our filter to correctly classify spam messages as being spam, but we also want the filter to not incorrectly classify ham messages as spam. This requirement can be measured with the precision and recall metrics. Precision is the ratio of true positives (spam classified as spam) over all predicted positives (all messages classified as spam). Precision will be high when there are few false positives (ham classified as spam). Recall is ratio of true positives over all actual positives (all actual spam). Recall will be high when there are few false negatives (spam classified as ham). For this problem, we care more about precision then we do about recall. It is ok to let more spam get through the filter if it means legitimate messages will have a small chance of being flagged as spam.\n",
    "\n",
    "We evaluate the filter's precision and recall for $T = 0.5, 0.75, 0.95, 0.96, 0.97, 0.98$ and $0.99$. We will make a tradeoff between false positives and false negatives. We can't *only* care about precision, because an email service that is flooded with spam can be just as unfriendly as one where legitimate messages are flagged as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T = 0.5</th>\n",
       "      <th>T = 0.75</th>\n",
       "      <th>T = 0.95</th>\n",
       "      <th>T = 0.96</th>\n",
       "      <th>T = 0.97</th>\n",
       "      <th>T = 0.98</th>\n",
       "      <th>T = 0.99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.534722</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>0.486111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            T = 0.5  T = 0.75  T = 0.95  T = 0.96  T = 0.97  T = 0.98  \\\n",
       "precision  0.912621  0.919192  0.939759  0.939024  0.950000  0.948718   \n",
       "recall     0.652778  0.631944  0.541667  0.534722  0.527778  0.513889   \n",
       "\n",
       "           T = 0.99  \n",
       "precision  0.972222  \n",
       "recall     0.486111  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precision_and_recall(actual_spam, predicted_prob_spam, threshold):\n",
    "    predicted_spam = predicted_prob_spam > threshold\n",
    "    \n",
    "    precision = actual_spam[predicted_spam].sum() / predicted_spam.sum()\n",
    "    recall = predicted_spam[actual_spam].sum() / actual_spam.sum()\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "pr_5 = precision_and_recall(test_data['SPAM'], prob_spam, 0.5)\n",
    "pr_75 = precision_and_recall(test_data['SPAM'], prob_spam, 0.75)\n",
    "pr_95 = precision_and_recall(test_data['SPAM'], prob_spam, 0.95)\n",
    "pr_96 = precision_and_recall(test_data['SPAM'], prob_spam, 0.96)\n",
    "pr_97 = precision_and_recall(test_data['SPAM'], prob_spam, 0.97)\n",
    "pr_98 = precision_and_recall(test_data['SPAM'], prob_spam, 0.98)\n",
    "pr_99 = precision_and_recall(test_data['SPAM'], prob_spam, 0.99)\n",
    "\n",
    "pr = pd.DataFrame({'T = 0.5': pr_5, 'T = 0.75': pr_75, 'T = 0.95': pr_95, 'T = 0.96': pr_96, 'T = 0.97': pr_97, 'T = 0.98': pr_98, 'T = 0.99': pr_99}, \n",
    "                  index=['precision', 'recall'])\n",
    "pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the most improvement in precision from 0.95-0.99. A 95% precision should be adequate, so we choose $T = 0.97$. This leaves almost 50% of spam unfiltered, and the precision could definitely be better. In a real world scenario, the best thing to do here would probably be to collect better data and try different techniques to build a better filter, rather than making more tradeoffs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Vangelis Metsis, Ion Androutsopoulos, and Georgios Paliouras. Spam Filtering with Naive Bayes - Which Naive Bayes? *CEAS 2006 - Third Conference on Email and Anti-Spam*, July 27-28, 2006, Mountain View, California USA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
