{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayesian Spam Filter\n",
    "\n",
    "This is the code to fit a Naive Bayesian Spam Filter to the \"SMS Spam Collection Dataset\" created by Tiago A. Almeida and José María Gómez Hidalgo.<sup>1</sup>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "We load the data from a csv file, the first and second columns are named 'v1' and 'v2,' which we rename to 'LABEL' and 'SMS.' The other columns are unnecessary so we remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_data = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "sms_data = sms_data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\n",
    "sms_data = sms_data.rename(columns={'v1': 'LABEL', 'v2': 'SMS'})\n",
    "\n",
    "print(sms_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sample randomly from the data to create the train and test splits, 80% of the data is used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sms_data.sample(frac=0.8,random_state=1).reset_index(drop=True)\n",
    "test_data = sms_data.drop(train_data.index).reset_index(drop=True)\n",
    "train_data = train_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clean the training and test data, replacing any punctuation with whitespace, as punctuation is not considered in the spam filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(data):\n",
    "    data_clean = data.copy()\n",
    "    data_clean['SMS'] = data['SMS'].str.replace('\\W+', ' ').str.replace('\\s+', ' ').str.strip()\n",
    "    data_clean['SMS'] = data_clean['SMS'].str.lower()\n",
    "    data_clean['SMS'] = data_clean['SMS'].str.split()\n",
    "\n",
    "train_data_clean = clean(train_data)\n",
    "test_data_clean = clean(test_data)\n",
    "\n",
    "print(train_data_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we turn each email in the train data into a vector of word counts where email['word'] denotes how often that word appears in the email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(set(train_data_clean['SMS'].sum()))\n",
    "word_counts_per_sms = pd.DataFrame([\n",
    "    [row[1].count(word) for word in vocabulary]\n",
    "    for _, row in train_data_clean.iterrows()], columns=vocabulary)\n",
    "train_data_clean = pd.concat([train_data_clean.reset_index(), word_counts_per_sms], axis=1).iloc[:,1:]\n",
    "\n",
    "print(train_data_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save this to a csv so that the production model can use it, we also save the test data for later testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_data.csv', 'w') as train_data_file:\n",
    "    train_data_clean.to_csv(train_data_file)\n",
    "\n",
    "with open('test_data.csv', 'w') as test_data_file:\n",
    "    test_data.to_csv(test_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Filter\n",
    "\n",
    "Now that the training data is prepared, we can classify emails. Below are the probabilities of an email being spam or ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_spam = train_data['LABEL'].value_counts()['spam'] / train_data.shape[0]\n",
    "prob_ham = train_data['LABEL'].value_counts()['ham'] / train_data.shape[0]\n",
    "\n",
    "num_spam = train_data.loc[train_data['LABEL'] == 'spam', 'SMS'].apply(len).sum()\n",
    "num_ham = train_data.loc[train_data['LABEL'] == 'ham', 'SMS'].apply(len).sum()\n",
    "vocab_size = len(train_data.columns) - 3\n",
    "\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above info, we can calculate the conditional probability that an email is spam or ham given that it contains some word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_if_spam(word):\n",
    "    if word in train_data.columns:\n",
    "        return (train_data.loc[train_data['LABEL'] == 'spam', word].sum() + alpha) / (num_spam + alpha * vocab_size)\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def prob_if_ham(word):\n",
    "    if word in train_data.columns:\n",
    "        return (train_data.loc[train_data['LABEL'] == 'ham', word].sum() + alpha) / (num_ham + alpha * vocab_size)\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have the algorithm to predict whether an email is spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "    prob_message_is_spam = prob_spam\n",
    "    prob_message_is_ham = prob_ham\n",
    "    \n",
    "    for word in message:\n",
    "        prob_message_is_spam *= prob_if_spam(word)\n",
    "        prob_message_is_ham *= prob_if_ham(word)\n",
    "    \n",
    "    if prob_message_is_spam > prob_message_is_ham:\n",
    "        return 'spam', prob_message_is_spam, prob_message_is_ham\n",
    "    else:\n",
    "        return 'ham', prob_message_is_spam, prob_message_is_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    "We grade the model based on its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade():\n",
    "    count = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for _, row in test_data.iterrows():\n",
    "        count += 1\n",
    "        if classify(row['SMS'])[0] == row['LABEL']:\n",
    "            correct += 1\n",
    "    \n",
    "    return correct / count, correct, count\n",
    "\n",
    "print(grade())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
